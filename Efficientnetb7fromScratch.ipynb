{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "OurEfficientnetb7fromscratch1.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rREuFNq1sXps"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class Swish(nn.Module):\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return x * torch.sigmoid(x)\n",
        "\n",
        "\n",
        "class Flatten(nn.Module):\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return x.reshape(x.shape[0], -1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6Sp-82PsXpv"
      },
      "source": [
        "Now let's define `SqueezeExcitation` module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmvJRZQosXpw"
      },
      "source": [
        "class SqueezeExcitation(nn.Module):\n",
        "    \n",
        "    def __init__(self, inplanes, se_planes):\n",
        "        super(SqueezeExcitation, self).__init__()\n",
        "        self.reduce_expand = nn.Sequential(\n",
        "            nn.Conv2d(inplanes, se_planes, \n",
        "                      kernel_size=1, stride=1, padding=0, bias=True),\n",
        "            Swish(),\n",
        "            nn.Conv2d(se_planes, inplanes, \n",
        "                      kernel_size=1, stride=1, padding=0, bias=True),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_se = torch.mean(x, dim=(-2, -1), keepdim=True)\n",
        "        x_se = self.reduce_expand(x_se)\n",
        "        return x_se * x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-AL5AYysXpw"
      },
      "source": [
        "from torch.nn import functional as F\n",
        "\n",
        "\n",
        "class MBConv(nn.Module):\n",
        "\n",
        "    def __init__(self, inplanes, planes, kernel_size, stride, \n",
        "                 expand_rate=1.0, se_rate=0.25, \n",
        "                 drop_connect_rate=0.2):\n",
        "        super(MBConv, self).__init__()\n",
        "\n",
        "        expand_planes = int(inplanes * expand_rate)\n",
        "        se_planes = max(1, int(inplanes * se_rate))\n",
        "\n",
        "        self.expansion_conv = None        \n",
        "        if expand_rate > 1.0:\n",
        "            self.expansion_conv = nn.Sequential(\n",
        "                nn.Conv2d(inplanes, expand_planes, \n",
        "                          kernel_size=1, stride=1, padding=0, bias=False),\n",
        "                nn.BatchNorm2d(expand_planes, momentum=0.01, eps=1e-3),\n",
        "                Swish()\n",
        "            )\n",
        "            inplanes = expand_planes\n",
        "\n",
        "        self.depthwise_conv = nn.Sequential(\n",
        "            nn.Conv2d(inplanes, expand_planes,\n",
        "                      kernel_size=kernel_size, stride=stride, \n",
        "                      padding=kernel_size // 2, groups=expand_planes,\n",
        "                      bias=False),\n",
        "            nn.BatchNorm2d(expand_planes, momentum=0.01, eps=1e-3),\n",
        "            Swish()\n",
        "        )\n",
        "\n",
        "        self.squeeze_excitation = SqueezeExcitation(expand_planes, se_planes)\n",
        "        \n",
        "        self.project_conv = nn.Sequential(\n",
        "            nn.Conv2d(expand_planes, planes, \n",
        "                      kernel_size=1, stride=1, padding=0, bias=False),\n",
        "            nn.BatchNorm2d(planes, momentum=0.01, eps=1e-3),\n",
        "        )\n",
        "\n",
        "        self.with_skip = stride == 1\n",
        "        self.drop_connect_rate = torch.tensor(drop_connect_rate, requires_grad=False)\n",
        "    \n",
        "    def _drop_connect(self, x):        \n",
        "        keep_prob = 1.0 - self.drop_connect_rate\n",
        "        drop_mask = torch.rand(x.shape[0], 1, 1, 1) + keep_prob\n",
        "        drop_mask = drop_mask.type_as(x)\n",
        "        drop_mask.floor_()\n",
        "        return drop_mask * x / keep_prob\n",
        "        \n",
        "    def forward(self, x):\n",
        "        z = x\n",
        "        if self.expansion_conv is not None:\n",
        "            x = self.expansion_conv(x)\n",
        "\n",
        "        x = self.depthwise_conv(x)\n",
        "        x = self.squeeze_excitation(x)\n",
        "        x = self.project_conv(x)\n",
        "        \n",
        "        # Add identity skip\n",
        "        if x.shape == z.shape and self.with_skip:            \n",
        "            if self.training and self.drop_connect_rate is not None:\n",
        "                self._drop_connect(x)\n",
        "            x += z\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlPTQlFRsXpx"
      },
      "source": [
        "And finally, we can implement generic `EfficientNet`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CV2NfxZIsXpx"
      },
      "source": [
        "from collections import OrderedDict\n",
        "import math\n",
        "\n",
        "\n",
        "def init_weights(module):    \n",
        "    if isinstance(module, nn.Conv2d):    \n",
        "        nn.init.kaiming_normal_(module.weight, a=0, mode='fan_out')\n",
        "    elif isinstance(module, nn.Linear):\n",
        "        init_range = 1.0 / math.sqrt(module.weight.shape[1])\n",
        "        nn.init.uniform_(module.weight, a=-init_range, b=init_range)\n",
        "        \n",
        "        \n",
        "class EfficientNet(nn.Module):\n",
        "        \n",
        "    def _setup_repeats(self, num_repeats):\n",
        "        return int(math.ceil(self.depth_coefficient * num_repeats))\n",
        "    \n",
        "    def _setup_channels(self, num_channels):\n",
        "        num_channels *= self.width_coefficient\n",
        "        new_num_channels = math.floor(num_channels / self.divisor + 0.5) * self.divisor\n",
        "        new_num_channels = max(self.divisor, new_num_channels)\n",
        "        if new_num_channels < 0.9 * num_channels:\n",
        "            new_num_channels += self.divisor\n",
        "        return new_num_channels\n",
        "\n",
        "    def __init__(self, num_classes=1, \n",
        "                 width_coefficient=1.0,\n",
        "                 depth_coefficient=1.0,\n",
        "                 se_rate=0.25,\n",
        "                 dropout_rate=0.2,\n",
        "                 drop_connect_rate=0.2):\n",
        "        super(EfficientNet, self).__init__()\n",
        "        \n",
        "        self.width_coefficient = width_coefficient\n",
        "        self.depth_coefficient = depth_coefficient\n",
        "        self.divisor = 8\n",
        "                \n",
        "        list_channels = [32, 16, 24, 40, 80, 112, 192, 320, 1280]\n",
        "        list_channels = [self._setup_channels(c) for c in list_channels]\n",
        "                \n",
        "        list_num_repeats = [1, 2, 2, 3, 3, 4, 1]\n",
        "        list_num_repeats = [self._setup_repeats(r) for r in list_num_repeats]        \n",
        "        \n",
        "        expand_rates = [1, 6, 6, 6, 6, 6, 6]\n",
        "        strides = [1, 2, 2, 2, 1, 2, 1]\n",
        "        kernel_sizes = [3, 3, 5, 3, 5, 5, 3]\n",
        "\n",
        "        # Define stem:\n",
        "        self.stem = nn.Sequential(\n",
        "            nn.Conv2d(3, list_channels[0], kernel_size=3, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(list_channels[0], momentum=0.01, eps=1e-3),\n",
        "            Swish()\n",
        "        )\n",
        "        \n",
        "        # Define MBConv blocks\n",
        "        blocks = []\n",
        "        counter = 0\n",
        "        num_blocks = sum(list_num_repeats)\n",
        "        for idx in range(7):\n",
        "            \n",
        "            num_channels = list_channels[idx]\n",
        "            next_num_channels = list_channels[idx + 1]\n",
        "            num_repeats = list_num_repeats[idx]\n",
        "            expand_rate = expand_rates[idx]\n",
        "            kernel_size = kernel_sizes[idx]\n",
        "            stride = strides[idx]\n",
        "            drop_rate = drop_connect_rate * counter / num_blocks\n",
        "            \n",
        "            name = \"MBConv{}_{}\".format(expand_rate, counter)\n",
        "            blocks.append((\n",
        "                name,\n",
        "                MBConv(num_channels, next_num_channels, \n",
        "                       kernel_size=kernel_size, stride=stride, expand_rate=expand_rate, \n",
        "                       se_rate=se_rate, drop_connect_rate=drop_rate)\n",
        "            ))\n",
        "            counter += 1\n",
        "            for i in range(1, num_repeats):                \n",
        "                name = \"MBConv{}_{}\".format(expand_rate, counter)\n",
        "                drop_rate = drop_connect_rate * counter / num_blocks                \n",
        "                blocks.append((\n",
        "                    name,\n",
        "                    MBConv(next_num_channels, next_num_channels, \n",
        "                           kernel_size=kernel_size, stride=1, expand_rate=expand_rate, \n",
        "                           se_rate=se_rate, drop_connect_rate=drop_rate)                                    \n",
        "                ))\n",
        "                counter += 1\n",
        "        \n",
        "        self.blocks = nn.Sequential(OrderedDict(blocks))\n",
        "        \n",
        "        # Define head\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Conv2d(list_channels[-2], list_channels[-1], \n",
        "                      kernel_size=1, bias=False),\n",
        "            nn.BatchNorm2d(list_channels[-1], momentum=0.01, eps=1e-3),\n",
        "            Swish(),\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            Flatten(),\n",
        "            nn.Dropout(p=dropout_rate),\n",
        "            nn.Linear(list_channels[-1], num_classes)\n",
        "        )\n",
        "\n",
        "        self.apply(init_weights)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        f = self.stem(x)\n",
        "        f = self.blocks(f)\n",
        "        y = self.head(f)\n",
        "        return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXcs9FAZQ45H",
        "outputId": "5d1dfdbe-6b60-4be3-d330-75d5fca840db"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMBVZexzRjlw"
      },
      "source": [
        "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaKAI_jtRnIY",
        "outputId": "f8bbea67-d9c1-462b-a595-79b0f3bbe799"
      },
      "source": [
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tEhbJWnsXpy"
      },
      "source": [
        "All EfficientNet models can be defined using the following parametrization:\n",
        "```\n",
        "# (width_coefficient, depth_coefficient, resolution, dropout_rate)\n",
        "'efficientnet-b0': (1.0, 1.0, 224, 0.2),\n",
        "'efficientnet-b1': (1.0, 1.1, 240, 0.2),\n",
        "'efficientnet-b2': (1.1, 1.2, 260, 0.3),\n",
        "'efficientnet-b3': (1.2, 1.4, 300, 0.3),\n",
        "'efficientnet-b4': (1.4, 1.8, 380, 0.4),\n",
        "'efficientnet-b5': (1.6, 2.2, 456, 0.4),\n",
        "'efficientnet-b6': (1.8, 2.6, 528, 0.5),\n",
        "'efficientnet-b7': (2.0, 3.1, 600, 0.5),\n",
        "```    \n",
        "Let's define and train the third one: `EfficientNet-B0`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCuCoTHBsXpy"
      },
      "source": [
        "model = EfficientNet(num_classes=1, \n",
        "                     width_coefficient=2.0, depth_coefficient=3.1, \n",
        "                     dropout_rate=0.5).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWP4xLuASTSw"
      },
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from math import ceil\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import  DataLoader\n",
        "import torchvision.datasets as datasetes\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQGul5TsSOn2"
      },
      "source": [
        "import os\n",
        "import  pandas as pd\n",
        "from torch.utils.data import Dataset\n",
        "#from skimage import io\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efznYNr7SA2H"
      },
      "source": [
        "\n",
        "class cancer_data(Dataset):\n",
        "    def __init__(self,csv_file,root_dir,transform=None):\n",
        "        self.annot= pd.read_csv(csv_file)\n",
        "        self.root_dir=root_dir\n",
        "        self.transform=transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.annot)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_path =os.path.join(self.root_dir,self.annot.iloc[index , 0])\n",
        "        #print(self.annot.iloc[index ,0])\n",
        "        #print(self.annot.iloc[index, 1])\n",
        "        #image=io.imread(img_path)\n",
        "        image=Image.open(img_path)\n",
        "        image=image.resize((224,224))\n",
        "        y_label=torch.tensor(int(self.annot.iloc[index , 1]))\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return (image , y_label)\n",
        "        #return (torch.from_numpy(image),y_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbLIU7IlSes-"
      },
      "source": [
        "\n",
        "dataset_input=cancer_data(csv_file='/content/drive/MyDrive/rec.csv' , root_dir='/content/drive/MyDrive/img1/img' , transform=transforms.ToTensor())\n",
        "train_dataset=DataLoader(dataset=dataset_input ,batch_size=16 ,shuffle=True )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTFLmacVShX8"
      },
      "source": [
        "criteria= nn.BCEWithLogitsLoss()\n",
        "optimizer=optim.Adam(model.parameters(),0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ix_v_X1zSnl7",
        "outputId": "c44ae579-fca3-442e-bfb0-b1adb991a58d"
      },
      "source": [
        "for ep in range(15):\n",
        "    tot_loss=0\n",
        "    for batch_idx,(data ,target) in enumerate(train_dataset):\n",
        "         #convert data of image into 2D to 1D\n",
        "         #print(data.shape)\n",
        "         #print(target)\n",
        "         #print(batch_idx)\n",
        "         if batch_idx%66==0:\n",
        "            print(\"=\",end=\" \")\n",
        "         #print(target)\n",
        "         #forward i.e pass obtain data to algorithm\n",
        "         data=data.to(device)\n",
        "         scores=model(data)\n",
        "         #print(scores)\n",
        "         target=target.to(device)\n",
        "         target = target.unsqueeze(1)\n",
        "         target =target.float()\n",
        "         loss=criteria(scores,target)\n",
        "         #print(loss)\n",
        "         tot_loss+=loss\n",
        "         optimizer.zero_grad()\n",
        "         loss.backward()\n",
        "         optimizer.step()\n",
        "    print(\"Epoch {}/{}\".format(ep + 1, 15))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "= = = = = = = = = = = Epoch 1/15\n",
            "= = = = = = = = = = = Epoch 2/15\n",
            "= = = = = = = = = = = Epoch 3/15\n",
            "= = = = = = = = = = = Epoch 4/15\n",
            "= = = = = = = = = = = Epoch 5/15\n",
            "= = = = = = = = = = = Epoch 6/15\n",
            "= = = = = = = = = = = Epoch 7/15\n",
            "= = = = = = = = = = = Epoch 8/15\n",
            "= = = = = = = = = = = Epoch 9/15\n",
            "= = = = = = = = = = = Epoch 10/15\n",
            "= = = = = = = = = = = Epoch 11/15\n",
            "= = = = = = = = = = = Epoch 12/15\n",
            "= = = = = = = = = = = Epoch 13/15\n",
            "= = = = = = = = = = = Epoch 14/15\n",
            "= = = = = = = = = = = Epoch 15/15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFBuYrPvpbaH"
      },
      "source": [
        "torch.save(model,'Efficientnetb0007.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8BgQYFlGbiG"
      },
      "source": [
        "import torchvision.transforms as transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DG_u-HC-D8B",
        "outputId": "19f3734e-4b4f-4bb1-903a-55220e5f8361"
      },
      "source": [
        "transform=transforms.ToTensor()\n",
        "model = torch.load('Efficientnetb0007.h5',map_location=torch.device('cuda'))\n",
        "model.eval()\n",
        "import  pandas as pd\n",
        "df=pd.read_csv('/content/drive/MyDrive/benign.csv')\n",
        "DF=df.iloc[1:,0:2]\n",
        "#print(DF)\n",
        "total=DF.count()[0]\n",
        "tp=tn=fp=fn=0\n",
        "for i in range(total):\n",
        "    if(i!=0 and i%100==0):\n",
        "        print(\"=\",end=\" \")\n",
        "    image = Image.open('/content/drive/MyDrive/benign1/benign/'+str(DF.iloc[i][0]))\n",
        "    image = image.resize((224, 224))\n",
        "    image = transform(image)\n",
        "    target=int(DF.iloc[i][1])\n",
        "    x = image.unsqueeze(0)\n",
        "    out = model(x.to(device))\n",
        "    n = float(out.data[0][0]) >= 0.5\n",
        "    if(n and target==1):\n",
        "        tp+=1\n",
        "    if(n and target==0):\n",
        "        fp+=1\n",
        "    if(not n and target==1):\n",
        "        fn+=1\n",
        "    if(not n and target==0):\n",
        "        tn+=1\n",
        "print(\"= = = = = = = = = =\")\n",
        "print(\"True Positive: \"+str(tp))\n",
        "print(\"True Negative: \"+str(tn))\n",
        "print(\"False Positive:\"+str(fp))\n",
        "print(\"False Negative:\"+str(fn))\n",
        "Total=tp+tn+fp+fn\n",
        "acc=((tp+tn)/Total)*100\n",
        "print(\"Accuracy :  \"+str(acc)+\"%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "= = = = = = = = = = = = = = = = = = = = = =\n",
            "True Positive: 645\n",
            "True Negative: 408\n",
            "False Positive:0\n",
            "False Negative:197\n",
            "Accuracy :  84.24000000000001%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjUCNwu3sXpz"
      },
      "source": [
        "Number of parameters:"
      ]
    }
  ]
}